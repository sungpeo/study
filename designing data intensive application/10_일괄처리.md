목차
    1. 유닉스 도구로 일괄 처리하기
    2. 맵리듀스와 분산 파일 시스템
    3. 맵리듀스를 넘어서
 
 
시스템을 세 가지 유형으로 구분해보자.
 
서비스(온라인 시스템)
응답 시간이 서비스 성능의 중요한 지표가 되며, 
가용성이 매우 중요
 
일괄 처리 시스템(오프라인 시스템)
매우 큰 입력 데이터를 처리하는 것으로 수 분에서 수일이 걸리므로 사용자가 대기하지 않는다.
주요 성능 지표로 처리량이 대표적이며 특정 크기를 처리할 때 걸리를 시간으로 나타낸다
 
스트림 처리 시스템(준실시간 시스템)
온라인과 오프라인/일괄 처리 사이의 어딘가에 있기 때문에 near-real-time processing or nearline processing 이라 불린다.
요청에 대한 응답하지 않는다. 
일괄처리 작업과 다르게 입력 이벤트가 발생한 직후 작동하므로 지연 시간이 낮다.


유닉스 도구로 일괄 처리하기
 
nginx의 기본 액세스 로그 형식 예시를 참고 (p387)
 
단순 로그 분석
 
cat /var/log/nginx/access.log |
  awk '{print $7}' |
  sort |
  uniq -c |
  sort -r -n |
  head -n 5
 
 
연쇄 명령 대 맞춤형 프로그램
 
counts = Hash.new(0)
 
File.open('/var/log/nginx/access.log') do |file|
  fie.each do |line|
    url = line.split[6]
    counts[url] += 1
  end
end
 
top5 = counts.map{ |url, count| [count, url] }.sort.reverse[0...5]
top5.each{ |count, url| puts "#{count} #{url}" }
 
표면적인 문법의 차이를 빼고도두 가지 방법은 실행 흐름이 크게 다르다. 대용량 파일을 분석해 보면 차이가 확연히 드러난다.




정렬 대 인메모리 집계
 
어떤 접근법이 더 좋을지는 다른 URL이 얼마나 되느냐에 따라 다르다.
허용 메모리보다 작업 세트(고유 URL 수)가 크다면 정렬 접근법을 사용하는 것이 좋다. 정렬 접근법은 디스크를 효율적으로 사용하는데, 앞서 논의했던 76쪽 "SS테이블과 LSM 트리"에서 설명한 원리와 다르지 않다.
 
GNU Coreutils(리눅스)에 포함된  sort 유틸리티는 메모리보다 큰 데이터셋을 자동으로 디스크로 보내고 자동으로 여러 CPU 코어에서 병렬로 정렬한다. 앞에서 간단한 유닉스 연쇄 명령이 메모리 부족 없이 손쉽게 큰 데이터셋으로 확장 가능하다는 의미다.
 
유닉스 철학
 
1. 각 프로그램이 한 가지 일만 하도록 작성하라. 새 작업을 하려면 기존 프로그램을 고쳐 새로운 "기능"을 추가해 프로그램을 복잡하게 만들기보다는 새로운 프로그램을 작성하라.
2. 모든 프로그램의 출력은 아직 알려지지 않은 다른 프로그램의 입력으로 쓰일 수 있다고 생각하라. 불필요한 정보로 출력이 너저분해서는 안된다. 입력 형식으로 엄격하게 열을 맞춘다거나 이진 형태를 사용하지 마라. 대화형 입력을 고집하지 마라.
3. 소프트웨어를 빠르게 써볼 수 있게 설계하고 구축하라. 심지어 운영체제도 마찬가지다. 수 주 안에 끝내는 것이 이상적이다. 거슬리는 부분은 과감히 버리고 새로 구축하라.
4. 프로그래밍 작업을 줄이려면 미숙한 도움보단 도구를 사용하라. 도구를 빌드하기 위해 한참 둘러가야 하고 게다가 사용 후 바로 버린다고 할지라도 도구를 써라.
 
bash 같은 유닉스 셸을 사용하면 작은 프로그램들을 가지고 놀랄 만큼 강력한 데이터 처리 작업을 쉽게 구성할 수 있다. 유닉스에 이런 결합성을 부여하는 것은 무엇일까?
 
 
동일 인터페이스
 
유닉스에서 인터페이스는 파일(좀 더 정확히는 파일 디스크립터)이다.
동일 인터페이스로 아스키 텍스트는 큰 문제는 없지만 그다지 깔끔하지 않다.
 
동일한 데이터 모델인 데이터베이스 간에도 한쪽에서 다른 쪽으로 데이터를 옮기는 게 쉽지 않다. 데이터가 발칸화(Balkanization)되는 이유는 유닉스 도구와 같은 통합이 부족했기 때문이다.
 
 
로직과 연결의 분리
 
유닉스 도구의 다른 특징으로 표준 입력(stdin)과 표준 출력(stdout)을 사용한다는 점을 들 수 있다. 
파이프는 한 프로세스의 stdout을 다른 프로세스의 stdin과 연결한다. 이때 중간 데이터를 디스크에 쓰지 않고 작은 인메모리 버퍼를 사용해 프로세스 간 데이터를 전송한다. 
stdin과 stdout만으로 처리하고 싶다고 유닉스 접근법이 가장 좋다.
*  느슨한 결합(loose coupling)이나 지연 바인딩(late binding) 또는 제어 반전(inversion of control)이라고도 한다.
 
그러나 stdin과  stdout을 사용할 때 몇 가지 제약사항이 있다. 
* 여러개의 입력이나 출력이 필요한 경우 까다롭다.
* 프로그램의 출력을 파이프를 이용해 네트워크와 연결하지 못한다. (netcat, curl)
* 프로그램이 파일을 직접 열어 읽고 쓰거나 서브프로세스로 다른 프로그램을 구동하거나 네트워크 연결을 하면 I/O가 묶이게 됨으로써 유연함이 감소한다.
 
 
투명성과 실험
 
* 유닉스 명령에 들어가는 입력 파일은 불변으로 처리된다. 이것은 다양한 명령행 옵션을 사용해가며 원하는 만큼 명령을 수행하더라도 입력 파일에는 손상을 주지 않는다는 뜻이다.
* 어느 시점이든 파이프라인을 중단하고 출력을 파이프를 통해 less로 보내 원하는 형태의 출력이 나오는지 확인할 수 있다. 이런 검사 기능은 디버깅할 때 매우 유용하다.
* 특정 파이프라인 단계의 출력을 파일에 쓰고 그 파일을 다음 단계의 입력으로 사용할 수 있다. 이렇게 하면 전체 파이프라인을 다시 시작하지 않고 다음 단계부터 재시작할 수 있다.
 
관계형 데이터베이스의 질의 최적화 도구와 비교하면 불친절하고 단순하지만 놀랍도록 유용하다.
 
! 가장 큰 제약은 단일 장비에서만 실행된다는 점이다.
바로 이 점이 하둡 같은 도구가 필요한 이유다.
 
 
맵리듀스와 분산 파일 시스템
 
맵리듀스는 수천 대의 장비로 분산해서 실행이 가능하다는 점에서 차이가 있다.
유닉스 도구는 stdin과 stdout을 입력과 출력으로 사용하는데 맵리듀스 작업은 분산 파일 시스템 상의 파일을 입력과 출력으로 사용한다. 하둡 맵리듀스 구현에서 이 파일 시스템은 HDFS이다.
 
HDFS는 비공유 원칙을 기반으로 NAS(Network Attached Storage)와 SAN(Storage Area Netwrok) 아키텍처에서 사용하는 공유 디스크 방식과는 반대다.
* 공유 디스크 저장소는 중앙 집중 저장 장치를 사용하는 데 맞춤형 하드웨어를 사용하거나 파이버 채널(Fiber Channel)과 같은 특별한 네트워크 인프라를 사용하기도 한다.
* 반면, 비공유 방식은 특별한 하드웨어가 필요 없다. 일반적인 데이터센터 네트워크에 연결된 컴퓨터면 충분하다.
 
HDFS 소개
* 네임노드
    * 중앙서버로서, 특정 파일 블록이 어떤 장비에 저장됐는지 추적
* 복제
    * RAID와 같은 형태로 디스크가 실패하는 경우를 대비
    * 삭제 코딩(erasure coding) 방식을 사용해 복제보다 적은 부담으로 데이터 복구 가능
* 확장성
    * 수만 대의 장비를 묶어 실행 중이고 용량은 수백 페타바이트에 달한다.
 
 
맵리듀스 작업 실행하기
 
맵리듀스는 HDFS 같읕 분산 파일 시스템 위에서 대용량 데이터셋을 처리하는 코드를 작성하는 프로그래밍 프레임워크다.
맵리듀스의 데이터 처리 패턴은 로그 분석 예제와 상당히 비슷하다.
1. 입력 파일을 읽는다. 레코드로 쪼갠다. 웹 서버 로그 예제에서 로그의 각 줄이 레코드가 된다.
2. 각 입력 레코드마다 매퍼 함수를 호출해 키와 값을 추출한다. URL($7)을 키로 추출하고 값은 빈 값으로 한다.
3. 키를 기준으로 키-값 쌍을 모두 정렬한다. 이 과정은 로그 예제에서 첫 번째 sort 명령에 해당한다.
4. 정렬된 키-값 쌍 전체를 대상으로 리듀스 함수를 호출한다. 같은 키는 서로 인접하는데 그래서 같은 키를 가지는 값들은 따로 메모리 상에 상태를 따로 유지하지 않고도 쉽게 결합할 수 있다. 리듀서는 예제에서 uniq -c 명령에 해당한다. 이 명령은 키가 같으면서 인접한 레코드의 수를 센다.
 
2단계(맵)과 4단계(리듀스)는 사용자가 직접 작성한 데이터 처리 코드다.
1단계는 파일을 나누어 레코드를 만드는 데 입력 형식 파서를 쓴다.
3단계는 정렬 단계로 맵리듀스에 내재하는 단계라서 직접 작성할 필요가 없는데 매퍼의 출력은 리듀스로 들어가기 전에 이미 정렬됐기 때문이다.
 
웹 서버 로그 예제에서 5번째 단계를 보면 두 번째 정렬 명령어가 있는데 요청 수가 많은 URL 순으로 정렬하는 역할을 했다. 맵리듀스에서 두 번째 정렬이 필요하다면 두 번째 맵리듀스 작업을 구현하면 된다.
 
 
맵리듀스의 분산 실행
 
유닉스 명령어 파이프라인과의 가장 큰 차이점은 맵리듀스가 병렬로 수행하는 코드를 직접 작성하지 않고도 여러 장비에서 동시에 처리가 가능하다는 점이다.
 


그림 10-1은 하둡 맵리듀스 작업에서 데이터플로를 보여준다. 맵리듀스 작업의 병렬 실행은 파티셔닝을 기반으로 한다. 작업 입력으로 HDFS 상의 디렉터리를 사용하는 것이 일반적이고, 입력 디렉터리 내 각 파일 또는 파일 블록을 독립된 맵 태스크에서 처리할 독립 파티션으로 간주한다.
 
맵
* 맵 태스크에서 실행된 애플리케이션 코드는 적절한 장비(컴퓨터 리소스가 충분하고 입력 파일이 가까운)로 코드를 복사한다.
* 입력 파일을 읽기 시작하면 입력 파일에서 한 번에 레코드 하나씩 읽어 매퍼 콜백 함수로 전달한다.
* 맵 태스크는 키의 해시값을 기반으로 출력을 파티셔닝하는데 각 파티션을 매퍼의 로컬 디스크에 정렬된 파일로 기록한다. 여기서 사용한 기술은 76쪽 "SS테이블과 LSM 트리"에서 설명한 것과 유사하다.
    *  파티셔닝 내에서 키는 정렬되어 있으므로
리듀서
* 맵 태스크 수는 입력 파일의 블록 수로 결정되지만 리듀스 태스크 수는 사용자가 설정한다.
* 매퍼가 출력 파일 기록을 완료를 맵리듀서 스케줄러가 알려주고, 매퍼로부터 데이터 파티션을 복사흔하는 과정을 셔플(suffle)이라 한다.
* 매퍼로부터 파일을 가져와 정렬된 순서를 유지하면서 병합하여 임의의 로직을 사용하여 레코드를 처리한다.
* 출력 레코드는 분산 파일 시스템에 파일로 기록된다.
 
 
맵리듀스 워크플로
 
단일 맵리듀스 작업으로 해결할 수 있는 문제의 범위는 제한저기므로 여러 작업을 연결해 워크플로(workflow)를 구성하는 것이 일반적이다.
일괄 처리 작업의 출력은 성공적으로 끝났을 때만 유효하고 실패하면 부분 출력은 제거한다.
Oozie, Azkaban, Luigi, Aiflow, Pinball 등의 스케줄러로 직접 연결하거나 고수준 도구 Pig, Hive, Cascading, Crunch, FlumeJava를 통해 사용한다.
 
 
리듀스 사이드 조인과 그룹화
 
데이터셋에서 레코드 사이의 연관이 있는 것은 일반적이다
* 관계형 모델: 외래키(foreign key)
* 문서 모델: 문서 참조(document reference)
* 그래프 모델: 간선(edge)
 
데이터베이스에서 적은 수의 레코드 관련해서 색인(index)을 사용해 조인을 수행하지만,
맵리듀스에서는 색인 개념이 없을 뿐더러 분석 질의의 경우 대량의 레코드를 대상으로 집계 연산이 일반적이므로 전체 테이블 스캔(full table scan)을 하는 것도 합리적이라 할 수 있다.
 
 
사용자 활동 이벤트 분석 예제
 
일괄 처리에서 처리량을 높이기 위해 그리고 결정적인 처리를 수행하기 위해 사용되는 방법으로
사용자 데이터베이스(여러 차원 중 하나: 조인 대상 데이터)의 사본을 사용자 활동 이벤트 로그(사실 테이블)가 저장된 분산 파일 시스템에서 넣고, 효율적인 처리가 가능하다.
 
정렬 병합 조인
 
그림 10-3
매퍼에서 다른 형태의 데이터를 같은 키(ex. user id)로 정렬하고, 
리듀서에서는 양측의 정렬된 레코드 목록을 그 키를 기준으로 데이터를 병합한다.
 
같은 곳으로 연관된 데이터 가져오기
 
같은 키를 가진 키-값 쌍은 모두 같은 목적지로 배달된다(같은 리듀서를 호출한다).
 
 
그룹화
 
조인 외에도 "같은 곳으로 관련 데이터를 모으는 " 일반적인 사용 유형은 SQL에서 GROUP BY 절과 같이 특정 키로 레코드를 그룹화하는 것이다.
요청을 받는 웹 서버가 여러개라면 이벤트가 분산된다. 세션 쿠키 사용자 ID나 유사한 식별자를 그룹화키로 한 곳으로 모으면 세션화(sessionization)을 구현할 수 있다.
 
 
쏠림 다루기
 
키 하나에 너무 많은 데이터가 연관되면 "같은 키를 가지는 모든 레코드를 같은 장소로 모으는" 패턴이 제대로 작동하지 않는다.
이렇게 불균형한 활성 데이터베이스 레코드를 린치핀 객체(linchipin object), or hot key라고 한다.
 
핫스팟을 완화할 알고리즘
* 쏠림 조인(skewed join) 메서드는 어떤키가 핫키인지 결정하기 위해 샘플링을 수행하고, 핫 키를 여러 리듀서에 퍼뜨려서 처리하게 하는 방법
* 하이브에서는 메타데이터에 명시적으로 핫키를 지정하고 레코드를 별도 파일에 저장했다가 맵 사이드 조인(map-side join)을 사용해 처리한다.
    * 1단계: 레코드를 임의의 리듀서로 보내서 일부를 그룹화 및 키별 집계
    * 2단계: 첫 단계 모든 리듀서에서 나온 값을 키별로 모두 결합
 
맵 사이드 조인
 
리듀스 사이드 조인(reduce-side join)은 특정한 가정 없이 매퍼가 조인을 준비하고 리듀서로 복사해서 입력을 병합한다.
반면 입력 데이터에 대한 특정 가정이 가능하다면 맵사이드 조인(map-side join)으로 불리는 기법을 사용해 더 빠르게 수행할 수 있다.
 
 
브로드캐스트 해시 조인
 
작은 데이터 셋을 모든 매퍼에 브로드캐스트하여 인메모리 해시 테이블로 매퍼에서 조인을 수행한다.
 
 
파티션 해시 조인
 
같은 방식으로 맵 사이드 조인의 입력을 파티셔닝하여 각 파티션에 독립적으로 적용할 수 있다.
이 방법은 각 매퍼의 해시 테이블에 적재해야할 데이터의 양을 줄일 수 있다.
파티션 해시 조인(partitioned hash join)을 하이브에서는 버킷 맵 조인(bucketed map join)이라 한다.
 
 
맵 사이드 병합 조인
 
입력 데이터셋이 같은 방식으로 파티셔닝됐을 뿐 아니라 같은 키를 기준으로 정렬됐다면 변형된 맵 사이드 조인을 적용할 수 있다.
파티셔닝 및 정렬된 데이터셋이 다른 용도로도 필요한 경우에 저장해놓고 다음 작업의 매퍼에서 조인을 하는 것이다.
 
 
맵 사이드 조인을 사용하는 맵리듀스 워크플로
 
맵 사이드 조인은 입력 파일 형태 그대로 조인이 되고 리듀스 사이드 조인은 조인 키로 파티셔닝하고 정렬되서 출력되는 차이가 있다.
또한 맵 사이드 조인은 크기, 정렬, 파티셔닝 (파티션 수, 어떤 키, 정렬 여부) 같은 제약 사항을 미리 파악해야 한다. 
하둡에서는 관련 메타 데이터를 관리하는데 HCatalog나  Hive 메타스토어를 사용하기도 한다.
 
 
일괄 처리 워크플로의 출력
 
데이터베이스 질의의 경우 트랜잭션 처리(OLTP)를 분석 목적과 구별했다.
일괄처리는 일반적으로 분석에 더 가깝지만 같다고 할 수 없다. 일괄 처리의 출력은 흔히 보고서가 아닌 다른 형태의 구조다.
 
 
검색 색인 구축
 
맵리듀스는 구글에서 검색 엔진에 사용할 색인을 구축하기 위해 처음 사용됐다.
루씬 같은 전문 색인은 용어 사전 파일로서 효율적으로 특정 키워드를 조회해 키워드가 포함된 문서 ID의 목록을 찾는다. 이것은 검색의 가장 단편적인 기능으로 검색 결과를 관련성 순으로 순위를 매기고 오타를 수정하고 동의어 문제를 해결하는 등 현실적인 문제를 해결하기 위해서는 다양한 부가 데이터가 필요하다. 그러나 기본 원리는 그대로 유지된다.
 
정해진 문서 집합을 대상으로 전문 검색이 필요하면, 일괄처리가 매우 효율적이다.
매퍼는 필요에 따라 문서 집합을 파티셔닝하고
각 리듀서가 해당 파티션에 대한 색인을 구축한다.
키워드로 검색 색인에 질의하는 연산은 읽기 전용이라서 색인 파일을 한번 생성하면 불변이다.
 
색인된 문서 집합이 변하면 전체 문서 집합을 대상으로 주기적인 전체 색인 워크플로 재수행을 할 수 있다.
다른 방법으로 증분 색일을 구축할 수도 있다. 루씬은 세그먼트 파일을 새로 기록하고 백그라운드에서 증분식으로 부분 파일을 병합하고 압축한다. 이런 처리 과정은 11장에서
 
 
일괄 처리의 출력으로 키-값을 저장
 
일괄처리 작업의 출력은 흔히 일종의 데이터베이스가 되는데, 어떻게 사용하는 것이 좋을까?
 
데이터베이스 서버로 직접 요청하는 방법은 유효하지만 좋은 아이디어는 아니다.
* 네트워크 요청이 포함되므로 성능이 떨어진다.
* 데이터베이스가 과부하에 빠져 질의 성능에 영향을 줄 뿐더러 시스템적인 문제를 야기시킬 수도 있다.
* 맵리듀스는 성공한 작업만 출력을 생성하도록 보장하는데 외부 시스템에 기록하면 복잡성이 올라간다.
 
맵리듀스 작업 내에서 데이터베이스 파일을 구축하는 것이 좋다.
*  볼드모트, 테라핀, 엘리펀트DB, Hbase 벌크 적재 등이 있다.
 
볼드모트를 예로, 데이터 복사하는 동안 기존 데이터로 요청을 처리하다가 복사 완료 후 원자적으로 새 파일로 바꾼다.
파일을 불변으로 사용하므로 문제가 발생해도 쉽게 기존 파일로 전환할 수 있다.
 
 
일괄 처리 출력에 관한 철학
 
전반부에서 유닉 철학에서처럼 입력은 변하지 않은 채 새 출력이 출력을 만들어내므로 부수 효과가 없다.
그래서 일괄 처리 작업은 좋은 성능을 내면서도 유지보수가 훨씬 간단하다.
* 인적 내결함성 : 코드에 버그가 있어 출력이 오염됐다면 코드를 이전버전으로 돌리고 작업을 재수행하면 된다.
* 비가역성 최소화
* 재시도를 통해 일시적 문제를 해결하며 맵리듀스 프레임워크가 실패한 출력을 폐기한다.
* 유닉스 도구와 마찬가지로 입출력 디렉터리를 설정하는 드으이 연결 작업과 로직을 분리한다.
 
유닉스와 차이점으로 하둡에서는 구조화된 파일 형식을 사용하면 저수준 구문 변환 작업 중 일부를 하지 않아도 된다.
*  Avro, Parquet
 
 
하둡과 분산 데이터베이스의 비교
 
맵리듀스 논문이 발간됐을 때 어떻게 보면 맵리듀스는 전혀 새로운 개념이 아니었다. 처리 알고리즘과 병렬 조인 알고리즘은 대규모 병렬 처리(Massively Parallel Processing, MPP) 데이터베이스라 불리는 것에서 모두 구현됐다.
* MPP 데이터베이스는 장비 클러스터에서 분석 SQL 질의를 병렬로 수행하는 것에 초점
* 맵리듀스와 분산 파일 시스템의 조합은 아무 프로그램이나 실행할 수 있는 운영체제와 비슷한 속성을 제공
 
 
저장소의 다양성
 
하둡은 데이터가 어떤 형태라도 상관없이 덤프할 수 있는 가능성을 열어 놓았다. 처리는 덤프 이후에 생각한다.
원시 데이터를 수집하고 스키마 설계는 나중에 고민하면 데이터 수집의 속도가 올라간다.("데이터 호수(data lake)" 또는 "엔터프라이즈 데이터 허브(enterprise data hub)"라고 알려진 개념)
 
따라서 하둡은 ETL 프로세스를 구현하는 데 종종 사용되기도 한다. 덤프한 뒤 데이터를 정리하고 관계형으로 변환하여 MPP 데이터웨어 하우스로 옮기는 식이다.
 
 
처리 모델의 다양성
 
Hive를 사용해 SQL 질의 실행 엔진을 구축하는 등, 하둣 플래솦ㅁ의 개방성 때문에 MPP 데이터베이스에서는 불가능했던 모든 범위의 접근법을 구현할 수 있었다.
* Hbase와 같은 임의 접근 가능한 OLTP 데이터베이스
* Impala 같은 MPP 스타일의 분석 데이터베이스
 
 
빈번하게 발생하는 결함을 줄이는 설계
 
맵리듀스는 대용량 작업을 가정하기 때문에, 데이터를 디스크에 되도록 기록하려고 한다.
태스크별 재처리가 가능하고 내결함성을 확보할 수 있다.
문제는 이 정도로 내결함성을 확보하기 위해 오버헤드를 감당하는 가치가 있을까?
 
구글에서는 온라인 프로덕션 서비스와 오프라인 일괄 처리 작업을 같읕 장비에서 실행하면서 우선 순위를 관리를 한다.
우선 순위가 높은 작업이 선점하면서 태스크를 종료할 가능성이 높았기 때문에 의미가 있었다.
 
 
맵리듀스를 넘어
 
맵리듀스를 직접 사용하는 일이 어려워서 추상화된 다양한 고수준 프로그래밍 모델이 등장했다.
나머지 장에서는 맵리듀스 대안을 살펴보자.
 
 
중간 상태 구체화
 
모든 맵리듀스 작업이 독립적이므로 작업 단계마다 중간 상태(Intermediate state)를 파일로 기록(구체화: materialization)한다.
그러나 대개 각 작업의 출력이 같은 팀 내의 다른 작업의 입력으로만 사용된다.
 
하지만 유닉스는 작은 인메모리 버퍼를 통해 출력을 입력으로 스트리밍한다. 
이로 인한 맵리듀스의 여러 단점이 있다.
* 선행 작업이 완료됐을 때만 시작 가능하다.
* 매퍼는 이전 리듀서 작업과 중복되기도 한다.
* 분산 파일 시스템에서 중간 상태를 저장하는 여러 장비에 걸쳐 복제하는 것인데 임시 데이터에게는 과잉 조치이다.
 
 
데이터플로 엔진
 
이러한 문제를 해결하기 위해 몇가지 엔진이 개발되었다. ex. 스파크, 테즈, 플링크
엔진들은 이러한 특성을 가진다.
* 전체 워크플로를 작업 하나로서 다룬다.
* 데이터 흐름을 모델링하기 때문에, dataflow engine이라고 부른다.
* 맵리듀스와 달리 연산자(operator)를 유연하게 연결할 수 있다.
 
 
맵리듀스 모델과 비교했을 때는 이런 장점이 있다.
    * 정렬과 같은 비싼 작업은 필요할 때만
    * 스케줄러를 통해 지역성 최적화가 가능
    * 연산자 간 중간 상태를 메모리나 로컬 디스크에만 기록 가능(HDFS에 쓰지 않고)
    * 연산자 JVM 재활용
 
 
내결함성
 
스파크와 플링크, 테즈는 HDFS에 중간 상태를 쓰지 않기 때문에 내결함성 확보를 위해 다른 접근법을 사용한다.
유효한 데이터로부터 계산을 다시 해서 복구한다. 그러기 위해서는 연산자를 결정적으로 만드는 것이 좋다.
* 스파크는 RDD 추상화를 통한 데이터 리니지 사용
* 플링크는 연산자 상태를 체크포인트 저장
 
연산자가 비결정적인 경우 다운스트림 연산자도 죽이고 신규 데이터를 기준으로 다시 수행하는 방법이 일반적이다. //비결정적인 데이터는 복구할 수 없다?!
 
 
구체화에 대한 논의
 
데이터 플로 엔진을 사용할때 구체화된 데이터셋은 보통 작업의 입력과 최종 출력이다.
개선된 점은 중간 상태를 파일 시스템에 기록하는 수고를 덜어준다는 점이다.
 
 
그래프와 반복 처리
 
전체 그래프에서 오프라인으로 처리를 수행하거나 분석을 하는 등 일괄처리 맥락에서 살펴보자.
반복적으로 간선을 따라가는 방식으로 목록(i부터 j까지 경로가 존재하는지)를 만드는 알고리즘을 이행적 폐쇄(transitive closure)라 한다.
이런 알고리즘은 반복적 스타일로 구현되는데 스케줄러+맵리듀스 접근법은 상당히 비효율적이다.
 
 
프리글 처리 모델
 
벌크 동기식 병렬(bulk synchronous parallel, BSP) 연산모델. (ex. Pregel, Apache Giraph, 스파크 GraphX, 플링크 Gelly)
 
정점은 반복에서 사용한 메모리 상태를 기억하고,
정점에서 다른 정점으로 간선을 따라 메시지를 보내며 함수를 호출한다. 
정점 상태를 제외하면 메시지는 내결함성과 지속성이 있다.
 
 
내결함성
 
프리글 모델은 반복 사이의 메시지 도착을 보장한다. 네트워크 상의 문제로 사라지거나 중복되거나 지연되더라도 목적디 정점에서 정확히 한 번만 처리된다.
맵리듀스처럼 알고리즘 구현 프로그래밍 모델을 단순화하기 위해 프리글 프레임워크 차원에서 완벽히 결함을 복구한다.
반복이 끝나는 시점에 모든 정점의 상태를 주기적으로 체크포인트로 저장함으로써 보장된다. 즉 전체 상태를 지속성 있는 저장소에 기록한다.
앞에서의 데이터플로 엔진 설명 때처럼 알고리즘이 결정적이고 메시지가 로그에 남는다면 손실된 파티션만 선택해서 복구할 수도 있다.
 
 
병렬 실행
 
알고리즘 상 정점이 어디에서 실행되는지는 중요하지 않으므로 프리글 프레임워크가 정점을 어디서 실행할지 어떻게 파티셔닝할지를 결정한다.
 
이상적으로는 빈번하게 통신하는 정점끼리는 같은 장비에 있어야 좋으나 
최적화하여 분할하기 어렵기 때문에 결과적으로 통신 오버헤드가 많이 발생한다.
 
그래서 그래프가 크지 않으면 단일 장비에 넣는게 훨씬 성능이 좋을 가능성이 높다. 
메모리에 들어갈 정도는 아니라면 디스크에 쓰는 GraphChi도 쓸만한 방법이다.
 
그래프가 너무 크면 분산 접근법을 꼭 사용해야 한다. 
효율적인 병렬 그래프 알고리즘은 지금도 연구가 진행 중이다.
 
 
고수준 API와 언어
 
고수준 인터페이스를 사용하면서 코드를 적게 작성해도 될 뿐더러
대화식 사용도 지원하기 때문에 데이터셋을 조사하고 처리하며 여러 접근법을 실험하기에 매우 유용하다.
 
 
선언형 질의 언어로 전환
 
조인을 수행하는 코드를 작성하기보다는 관계형 연산자로 조인을 나타내면 프레임워크가 앞서 기술한 조인 알고리즘 중에 어떤 방법이 좋을지 결정할 수 있다는 장점이 있다.
하이브, 스파크, 플링크는 비용기반의 질의 최적화기를 내장하고 있으며 중간 상태를 최소화하기 위해 조인 순서를 바꾸기도 한다.
데이터플로 엔진도 선언적인 기능을 통합하여 질의 최적화기를 잘 사용하면 유연성을 유지하면서도 MPP 데이터베이스와 비슷하게 사용할 수 있다.
 
 
다양한 분야를 지원하기 위한 전문화
 
 
통계학과 수치 알고리즘의 중요성이 증가하고 있다.
* 머하웃: 맵리듀스, 스파크, 플링크 상에서 실행되는 다양한 머신러닝용 알고리즘 구현
* 매드립: 관계형 MPP 데이터베이스 내부에서 유사한 기능 구현
 
* k-nearest neighbor: 유사도 검색 알고리즘
 
* 일괄 처리 시스템: 내장기능과 고수준 선억적 연산자를 포함
* MPP 데이터베이스: 프로그래밍이 가능하게끔 유연
 
 
정리
유닉스를 시작으로 분산 일괄 처리 시스템을 살펴봤다.
입력은 불변이고 출력은 다른 프로그램의 입력으로 사용한다는 점이 같았다. (한가지 일을 잘하는 작은 도구 엮기)
* 유닉스에서는 파일과 파이프
* 맵리듀스에서는 분산 파일 시스템
* 데이터플로엔진은 파이프와 비슷하게 메모리를 사용, 출력은 분산 파일 시스템


분산 일괄 처리 프레임워크가 해결해야할 두가지 문제


1.파티셔닝
* 맵리듀스에서 매퍼는 입력파일에 따라 파티셔닝되고, 출력은 정렬해서 재 파티셔닝하고 리듀서 파티션으로 병합한다.
* 데이터플로 엔진은 필요한 경우에만 정렬을 한다.


2.내결함성
* 맵리듀스는 디스크에 자주 쓰는 대신 작업을 쉽게 복구할 수 있다.
* 데이터플로 엔진은 중간 상태를 최대한 구체화하지 않고 메모리에서 빠르게 처리한다. 복구를 위해 결정적 연산자를 잘 사용하는 것이 중요하다.




맵리듀스에서 사용하는 몇가지 조인 알고리즘


정렬 병합 조인
* 파티셔닝, 정렬, 병합 과정을 마친 같은 키를 가진 레코드가 하나의 리듀서로 호출된다.


브로드캐스트 해시 조인
* 상대적으로 작은 해시 테이블을 각 매퍼에 적재하고 조인한다.


파티션 해시 조인
* 조인 입력 두 개를 같은 방식으로 파티셔닝하면 해시 테이블 방식을 각 파티션별로 사용할 수 있다.


일괄 처리에서는 결정적으로 입력 데이터가 고정된 크기로 한정됐는데, 
다음 장에서 다룰 스트림처리에서는 입력이 한정되지 않는다.
